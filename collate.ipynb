{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = open(\"hf_links.txt\", \"r\").readlines()\n",
    "models = open(\"models.txt\", \"r\").readlines()\n",
    "\n",
    "links = [i.strip('# \\n\"') for i in links]\n",
    "models = [i.strip('# \"\\n') for i in models] \n",
    "\n",
    "m2l = {}\n",
    "for l, m in zip(links, models):\n",
    "    m2l[m] = \"https://huggingface.co/\" + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codellama-7b https://huggingface.co/codellama/CodeLlama-7b-hf\n",
      "codellama-13b https://huggingface.co/codellama/CodeLlama-13b-hf\n",
      "codellama-34b https://huggingface.co/codellama/CodeLlama-34b-hf\n",
      "codellama-python-7b https://huggingface.co/codellama/CodeLlama-7b-Python-hf\n",
      "codellama-python-13b https://huggingface.co/codellama/CodeLlama-13b-Python-hf\n",
      "codellama-python-34b https://huggingface.co/codellama/CodeLlama-34b-Python-hf\n",
      "codetulu-2-34b https://huggingface.co/allenai/codetulu-2-34b\n",
      "deepseek-base-1.3b https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base\n",
      "deepseek-base-6.7b https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base\n",
      "deepseek-base-33b https://huggingface.co/deepseek-ai/deepseek-coder-33b-base\n",
      "deepseek-instruct-1.3b https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct\n",
      "deepseek-instruct-6.7b https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct\n",
      "deepseek-instruct-33b https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct\n",
      "magicoder-ds-7b https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B\n",
      "mistral-7b https://huggingface.co/mistralai/Mistral-7B-v0.1\n",
      "mixtral-8x7b https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\n",
      "phi-1 https://huggingface.co/microsoft/phi-1\n",
      "phi-1.5 https://huggingface.co/microsoft/phi-1_5\n",
      "phi-2 https://huggingface.co/microsoft/phi-2\n",
      "phind https://huggingface.co/Phind/Phind-CodeLlama-34B-v2\n",
      "starcoderbase-7b https://huggingface.co/bigcode/starcoderbase-7b\n",
      "starcoderbase-16b https://huggingface.co/bigcode/starcoderbase\n",
      "wizard-13b https://huggingface.co/WizardLM/WizardCoder-Python-13B-V1.0\n",
      "wizard-34b https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0\n"
     ]
    }
   ],
   "source": [
    "for l, m in m2l.items():\n",
    "    print(l, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'codellama-7b+cot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     i1, i5 \u001b[39m=\u001b[39m i_scores[model]\n\u001b[1;32m     29\u001b[0m     o1, o5 \u001b[39m=\u001b[39m o_scores[model]\n\u001b[0;32m---> 30\u001b[0m     link \u001b[39m=\u001b[39m m2l[model]\n\u001b[1;32m     31\u001b[0m     rows\u001b[39m.\u001b[39mappend([model, i1, i5, o1, o5, link])\n\u001b[1;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'codellama-7b+cot'"
     ]
    }
   ],
   "source": [
    "def get_link(model_name):\n",
    "    if model_name.endswith(\"+cot\"):\n",
    "        model_name = model_name[:-4]\n",
    "    if \"gpt\" in model_name:\n",
    "        return \"https://platform.openai.com/docs/models\"\n",
    "    else:\n",
    "        return m2l[model_name]\n",
    "\n",
    "cei = open(\"cruxevali.txt\", \"r\").readlines()\n",
    "i_scores = {}\n",
    "for i in cei:\n",
    "    i = i.strip().split(\"|\")[1:-1]\n",
    "    i = [_i.strip() for _i in i]\n",
    "    model, p1, p5 = i[0], float(i[1]), float(i[2])\n",
    "    i_scores[model] = [p1, p5]\n",
    "\n",
    "ceo = open(\"cruxevalo.txt\", \"r\").readlines()\n",
    "o_scores = {}\n",
    "for o in ceo:\n",
    "    o = o.strip().split(\"|\")[1:-1]\n",
    "    o = [_i.strip() for _i in o]\n",
    "    model, p1, p5 = o[0], float(o[1]), float(o[2])\n",
    "    o_scores[model] = [p1, p5]\n",
    "\n",
    "fields = [\"Model\", \"i@1\", \"i@5\", \"o@1\", \"o@5\", \"link\"]\n",
    "rows = []\n",
    "for model in i_scores:\n",
    "    i1, i5 = i_scores[model]\n",
    "    o1, o5 = o_scores[model]\n",
    "    link = get_link(model)\n",
    "    rows.append([model, i1, i5, o1, o5, link])\n",
    "\n",
    "import csv\n",
    "with open(\"data.csv\", 'w') as csvfile:  \n",
    "    csvwriter = csv.writer(csvfile)  \n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codellama/CodeLlama-7b-hf https://huggingface.co/codellama/CodeLlama-7b-hf\n",
      "codellama/CodeLlama-13b-hf https://huggingface.co/codellama/CodeLlama-13b-hf\n",
      "codellama/CodeLlama-34b-hf https://huggingface.co/codellama/CodeLlama-34b-hf\n",
      "codellama/CodeLlama-7b-Python-hf https://huggingface.co/codellama/CodeLlama-7b-Python-hf\n",
      "codellama/CodeLlama-13b-Python-hf https://huggingface.co/codellama/CodeLlama-13b-Python-hf\n",
      "codellama/CodeLlama-34b-Python-hf https://huggingface.co/codellama/CodeLlama-34b-Python-hf\n",
      "allenai/codetulu-2-34b https://huggingface.co/allenai/codetulu-2-34b\n",
      "deepseek-ai/deepseek-coder-1.3b-base https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-base\n",
      "deepseek-ai/deepseek-coder-6.7b-base https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-base\n",
      "deepseek-ai/deepseek-coder-33b-base https://huggingface.co/deepseek-ai/deepseek-coder-33b-base\n",
      "deepseek-ai/deepseek-coder-1.3b-instruct https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct\n",
      "deepseek-ai/deepseek-coder-6.7b-instruct https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct\n",
      "deepseek-ai/deepseek-coder-33b-instruct https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct\n",
      "ise-uiuc/Magicoder-S-DS-6.7B https://huggingface.co/ise-uiuc/Magicoder-S-DS-6.7B\n",
      "mistralai/Mistral-7B-v0.1 https://huggingface.co/mistralai/Mistral-7B-v0.1\n",
      "mistralai/Mixtral-8x7B-v0.1 https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\n",
      "microsoft/phi-1 https://huggingface.co/microsoft/phi-1\n",
      "microsoft/phi-1_5 https://huggingface.co/microsoft/phi-1_5\n",
      "microsoft/phi-2 https://huggingface.co/microsoft/phi-2\n",
      "Phind/Phind-CodeLlama-34B-v2 https://huggingface.co/Phind/Phind-CodeLlama-34B-v2\n",
      "bigcode/starcoderbase-7b https://huggingface.co/bigcode/starcoderbase-7b\n",
      "bigcode/starcoderbase https://huggingface.co/bigcode/starcoderbase\n",
      "WizardLM/WizardCoder-Python-13B-V1.0 https://huggingface.co/WizardLM/WizardCoder-Python-13B-V1.0\n",
      "WizardLM/WizardCoder-Python-34B-V1.0 https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "execution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
